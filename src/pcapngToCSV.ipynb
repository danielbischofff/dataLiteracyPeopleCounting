{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T09:17:15.333728400Z",
     "start_time": "2024-01-16T09:17:14.793330500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import io\n",
    "import pandas as pd\n",
    "import csv\n",
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T09:17:15.350033600Z",
     "start_time": "2024-01-16T09:17:15.333728400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory containing the pcapng files\n",
    "pcapng_dir = \"C:\\\\Users\\\\Philipp\\OneDrive - UT Cloud\\\\Data_literacy_mensa\\\\Mensa_10-01-24\"\n",
    "\n",
    "# Directory to save the csv files\n",
    "csv_dir = \"C:\\\\Users\\\\Philipp\\OneDrive - UT Cloud\\\\Data_literacy_mensa\\\\Mensa_10-01-24\"\n",
    "\n",
    "# File name for merged CSV\n",
    "csvMerged = \"Wednesday100124.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T09:26:19.463257700Z",
     "start_time": "2024-01-16T09:17:15.583354700Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell can take upto 20 min to load\n",
    "def convert_pcapng_to_csv(pcapng_file):\n",
    "    # Full path to the pcapng file\n",
    "    pcapng_path = os.path.join(pcapng_dir, pcapng_file)\n",
    "    \n",
    "    if not os.path.exists(pcapng_path):\n",
    "        print(f\"Error: File {pcapng_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    csv_path = os.path.join(csv_dir, pcapng_file + '.csv')\n",
    "\n",
    "\n",
    "    commandPcapngToCsv = [\n",
    "    \"C:\\\\Program Files\\\\Wireshark\\\\tshark.exe\",\n",
    "    \"-r\",\n",
    "    pcapng_path,\n",
    "    \"-T\",\n",
    "    \"fields\",\n",
    "    \"-E\",\n",
    "    \"header=y\",\n",
    "    \"-E\",\n",
    "    \"separator=,\",\n",
    "    \"-E\",\n",
    "    \"quote=d\",\n",
    "    \"-E\",\n",
    "    \"occurrence=f\", \n",
    "    \"-e\",\n",
    "    \"frame.number\",\n",
    "    \"-e\",\n",
    "    \"frame.time\",\n",
    "    \"-e\",\n",
    "    \"wlan.sa\",\n",
    "    \"-e\",\n",
    "    \"wlan.da\",\n",
    "    \"-e\",\n",
    "    \"_ws.col.Protocol\",\n",
    "    \"-e\",\n",
    "    \"frame.len\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        with open(csv_path, \"w\") as f:\n",
    "            subprocess.run(commandPcapngToCsv, stdout=f, check=True)\n",
    "    except Exception as e:\n",
    "            print(f\"Error processing {pcapng_file}: {e}\")\n",
    "\n",
    "# def write_results_to_file(result_data, csv_path):\n",
    "#     # Write the results to a CSV file\n",
    "#     with open(csv_path, \"w\", newline='') as csv_file:\n",
    "#         fieldnames = [\"frame.number\", \"frame.time\", \"ip.src\", \"ip.dst\", \"_ws.col.Protocol\", \"frame.len\", \"_ws.col.Info\"]\n",
    "#         writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "# \n",
    "#         # Write the header\n",
    "#         writer.writeheader()\n",
    "# \n",
    "#         # Write the data\n",
    "#         writer.writerows(result_data)\n",
    "\n",
    "# Example usage with concurrent.futures\n",
    "pcapng_files = [f for f in os.listdir(pcapng_dir)]\n",
    "\n",
    "with mp.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    executor.map(convert_pcapng_to_csv, pcapng_files)\n",
    "    # # Submit the tasks for each file\n",
    "    # future_to_file = {executor.submit(convert_pcapng_to_csv, pcapng_file): pcapng_file for pcapng_file in pcapng_files}\n",
    "    # \n",
    "    # # Wait for the tasks to complete\n",
    "    # for future in mp.as_completed(future_to_file):\n",
    "    #     pcapng_file = future_to_file[future]\n",
    "    #     try:\n",
    "    #         result_data = future.result()\n",
    "    #         write_results_to_file(result_data, os.path.join(csv_dir, pcapng_file + '_parsed.csv'))\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error processing {pcapng_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T09:26:59.964767500Z",
     "start_time": "2024-01-16T09:26:19.473168400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of all csv files in the directory\n",
    "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "\n",
    "# # Read each csv file and append it to the list of dataframes\n",
    "dfs = [pd.read_csv(os.path.join(csv_dir, csv_file)) for csv_file in csv_files]\n",
    "\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new csv file\n",
    "df.to_csv(os.path.join(csv_dir, csvMerged), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T09:27:00.344466Z",
     "start_time": "2024-01-16T09:26:59.964767500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "326030"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wlan.sa'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataLiteracy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
